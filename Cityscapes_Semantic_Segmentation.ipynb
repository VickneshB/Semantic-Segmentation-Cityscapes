{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install albumentations\n",
        "!pip install opencv-python-headless matplotlib\n",
        "!pip install cityscapesscripts\n",
        "\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "4y_wugBZfSlu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NDIEcIH_nzL1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fkNM64mVeL3T"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms.functional as TF\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from torchvision import datasets, utils, transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from cityscapesscripts.helpers.labels import trainId2label as t2l\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = 'cuda:0'\n",
        "    print('Running on the GPU')\n",
        "else:\n",
        "    DEVICE = 'cpu'\n",
        "    print('Running on the CPU')\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UNET(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels=3, classes=19):\n",
        "        super(UNET, self).__init__()\n",
        "        self.layers = [in_channels, 64, 128, 256, 512, 1024]\n",
        "\n",
        "        self.double_conv_downs = nn.ModuleList(\n",
        "            [self.__double_conv(layer, layer_n) for layer, layer_n in zip(self.layers[:-1], self.layers[1:])])\n",
        "\n",
        "        self.up_trans = nn.ModuleList(\n",
        "            [nn.ConvTranspose2d(layer, layer_n, kernel_size=2, stride=2)\n",
        "             for layer, layer_n in zip(self.layers[::-1][:-2], self.layers[::-1][1:-1])])\n",
        "\n",
        "        self.double_conv_ups = nn.ModuleList(\n",
        "        [self.__double_conv(layer, layer//2) for layer in self.layers[::-1][:-2]])\n",
        "\n",
        "        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.final_conv = nn.Conv2d(64, classes, kernel_size=1)\n",
        "\n",
        "\n",
        "    def __double_conv(self, in_channels, out_channels):\n",
        "        conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        return conv\n",
        "\n",
        "    def forward(self, x):\n",
        "        concat_layers = []\n",
        "\n",
        "        for down in self.double_conv_downs:\n",
        "            x = down(x)\n",
        "            if down != self.double_conv_downs[-1]:\n",
        "                concat_layers.append(x)\n",
        "                x = self.max_pool_2x2(x)\n",
        "\n",
        "        concat_layers = concat_layers[::-1]\n",
        "\n",
        "        for up_trans, double_conv_up, concat_layer  in zip(self.up_trans, self.double_conv_ups, concat_layers):\n",
        "            x = up_trans(x)\n",
        "            if x.shape != concat_layer.shape:\n",
        "                x = TF.resize(x, concat_layer.shape[2:])\n",
        "\n",
        "            concatenated = torch.cat((concat_layer, x), dim=1)\n",
        "            x = double_conv_up(concatenated)\n",
        "\n",
        "        x = self.final_conv(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "HA1rx2udCq1u"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CityscapesDataset(Dataset):\n",
        "    def __init__(self, split, root_dir, target_type='semantic', mode='fine', transform=None, eval=False):\n",
        "        self.transform = transform\n",
        "        self.split = split\n",
        "        self.eval = eval\n",
        "\n",
        "        if mode == 'fine':\n",
        "            self.mode = 'gtFine'\n",
        "        elif mode == 'coarse':\n",
        "            self.mode = 'gtCoarse'\n",
        "\n",
        "        self.label_path = os.path.join(root_dir, 'gtFine_trainvaltest', self.mode, self.split)\n",
        "        self.rgb_path = os.path.join(root_dir, 'leftImg8bit_trainvaltest', 'leftImg8bit', self.split)\n",
        "\n",
        "        self.XImg_list = []\n",
        "        self.yLabel_list = []\n",
        "\n",
        "        city_list = os.listdir(self.rgb_path)\n",
        "\n",
        "        for city in city_list:\n",
        "            rgb_city_path = os.path.join(self.rgb_path, city)\n",
        "            rgb_images = os.listdir(rgb_city_path)\n",
        "\n",
        "            for img in rgb_images:\n",
        "                if img.endswith('_leftImg8bit.png'):\n",
        "\n",
        "                    self.XImg_list.append(os.path.join(city, img))\n",
        "\n",
        "\n",
        "                    label_img = img.replace('leftImg8bit', 'gtFine').replace('.png', '_labelIds.png')\n",
        "                    label_img_path = os.path.join(city, label_img)\n",
        "\n",
        "\n",
        "                    if os.path.exists(os.path.join(self.label_path, label_img_path)):\n",
        "                        self.yLabel_list.append(label_img_path)\n",
        "                    else:\n",
        "                        print(f\"Warning: Missing label for image {img}\")\n",
        "\n",
        "        print(f\"Number of images: {len(self.XImg_list)}, Number of labels: {len(self.yLabel_list)}\")\n",
        "        print(f\"First 5 images: {self.XImg_list[:5]}\")\n",
        "        print(f\"First 5 labels: {self.yLabel_list[:5]}\")\n",
        "\n",
        "        self.void_classes = [0, 1, 2, 3, 4, 5, 6, 9, 10, 14, 15, 16, 18, 29, 30, -1]\n",
        "        self.valid_classes = [7, 8, 11, 12, 13, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33]\n",
        "\n",
        "        self.class_mapping = {original: new for new, original in enumerate(self.valid_classes)}\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.XImg_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        max_attempts = 10\n",
        "        attempts = 0\n",
        "        image = None\n",
        "        y = None\n",
        "\n",
        "        while attempts < max_attempts:\n",
        "            try:\n",
        "                image = Image.open(os.path.join(self.rgb_path, self.XImg_list[index]))\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"Attempt {attempts + 1} failed to load image {self.XImg_list[index]}: {e}\")\n",
        "                attempts += 1\n",
        "\n",
        "        if image is None:\n",
        "            print(f\"Skipping image {self.XImg_list[index]} after {max_attempts} attempts.\")\n",
        "            return None\n",
        "\n",
        "        attempts = 0\n",
        "\n",
        "        while attempts < max_attempts:\n",
        "            try:\n",
        "                y = Image.open(os.path.join(self.label_path, self.yLabel_list[index]))\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"Attempt {attempts + 1} failed to load label {self.yLabel_list[index]}: {e}\")\n",
        "                attempts += 1\n",
        "\n",
        "        if y is None:\n",
        "            print(f\"Skipping label {self.yLabel_list[index]} after {max_attempts} attempts.\")\n",
        "            return None\n",
        "\n",
        "        image = transforms.ToTensor()(image)\n",
        "\n",
        "        y = np.array(y)\n",
        "        y_remapped = np.copy(y)\n",
        "\n",
        "        for void_class in self.void_classes:\n",
        "            y_remapped[y == void_class] = 255\n",
        "\n",
        "        for original_class, new_class in self.class_mapping.items():\n",
        "            y_remapped[y == original_class] = new_class\n",
        "\n",
        "        y = torch.from_numpy(y_remapped).type(torch.LongTensor)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        if self.eval:\n",
        "            return image, y, self.XImg_list[index]\n",
        "        else:\n",
        "            return image, y"
      ],
      "metadata": {
        "id": "OWWMk7e7eMvr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cityscapes_data(\n",
        "    mode,\n",
        "    split,\n",
        "    relabelled,\n",
        "    root_dir='/content/drive/MyDrive/Cityscapes/',\n",
        "    target_type=\"semantic\",\n",
        "    transforms=None,\n",
        "    batch_size=1,\n",
        "    eval=False,\n",
        "    shuffle=True,\n",
        "    pin_memory=True,\n",
        "\n",
        "):\n",
        "    data = CityscapesDataset(\n",
        "        mode=mode, split=split, target_type=target_type, transform=transforms, root_dir=root_dir, eval=eval)\n",
        "\n",
        "    data_loaded = torch.utils.data.DataLoader(\n",
        "        data, batch_size=batch_size, shuffle=shuffle, pin_memory=pin_memory)\n",
        "\n",
        "    return data_loaded\n",
        "\n",
        "def save_as_images(tensor_pred, folder, image_name):\n",
        "    tensor_pred = transforms.ToPILImage()(tensor_pred.byte())\n",
        "    filename = f\"{folder}\\{image_name}.png\"\n",
        "    tensor_pred.save(filename)"
      ],
      "metadata": {
        "id": "GDVHkhJ-eS6v"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LOAD_MODEL = True\n",
        "ROOT_DIR = '/content/drive/MyDrive/Cityscapes/'\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, 'MODEL/')\n",
        "IMG_HEIGHT = 1024\n",
        "IMG_WIDTH = 2048\n",
        "BATCH_SIZE = 1\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 20\n",
        "\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "def train_function(data, model, optimizer, loss_fn, device):\n",
        "    print('Entering into train function')\n",
        "    loss_values = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    data = tqdm(data)\n",
        "\n",
        "    for index, batch in enumerate(data):\n",
        "        X, y = batch\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        preds = model(X)\n",
        "\n",
        "        preds = preds.permute(0, 2, 3, 1)\n",
        "        preds = preds.reshape(-1, preds.shape[-1])\n",
        "        y = y.reshape(-1)\n",
        "\n",
        "        loss = loss_fn(preds, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(preds, 1)\n",
        "\n",
        "        total += y.size(0)\n",
        "        correct += (predicted == y).sum().item()\n",
        "\n",
        "        loss_values.append(loss.item())\n",
        "\n",
        "    avg_loss = sum(loss_values) / len(loss_values)\n",
        "    accuracy = correct / total * 100\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def main():\n",
        "    global epoch\n",
        "    epoch = 15\n",
        "\n",
        "    if LOAD_MODEL:\n",
        "        if not epoch:\n",
        "            MODEL_NAME = f'model.pth'\n",
        "            MODEL_PATH = os.path.join(MODEL_DIR, MODEL_NAME)\n",
        "        else:\n",
        "            MODEL_NAME = f'model_epoch{epoch-1}.pth'\n",
        "            MODEL_PATH = os.path.join(MODEL_DIR, MODEL_NAME)\n",
        "\n",
        "    LOSS_VALS = []\n",
        "    ACCURACY_VALS = []\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((IMG_HEIGHT, IMG_WIDTH), interpolation=Image.NEAREST),\n",
        "    ])\n",
        "\n",
        "    train_set = get_cityscapes_data(\n",
        "        split='train',\n",
        "        mode='fine',\n",
        "        relabelled=True,\n",
        "        root_dir=ROOT_DIR,\n",
        "        transforms=transform,\n",
        "        batch_size=BATCH_SIZE,\n",
        "    )\n",
        "\n",
        "    print('Data Loaded Successfully!')\n",
        "\n",
        "    unet = UNET(in_channels=3, classes=19).to(DEVICE).train()\n",
        "    optimizer = optim.Adam(unet.parameters(), lr=LEARNING_RATE)\n",
        "    loss_function = nn.CrossEntropyLoss(ignore_index=255)\n",
        "\n",
        "    if LOAD_MODEL:\n",
        "        print(f'Loading Model {MODEL_PATH}...')\n",
        "        checkpoint = torch.load(MODEL_PATH)\n",
        "        unet.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optim_state_dict'])\n",
        "        epoch = checkpoint['epoch'] + 1\n",
        "        LOSS_VALS = checkpoint['loss_values']\n",
        "        print(\"Model successfully loaded!\")\n",
        "\n",
        "    for e in range(epoch, EPOCHS):\n",
        "        print(f'Epoch: {e}')\n",
        "        avg_loss, accuracy = train_function(train_set, unet, optimizer, loss_function, DEVICE)\n",
        "        LOSS_VALS.append(avg_loss)\n",
        "        ACCURACY_VALS.append(accuracy)\n",
        "        MODEL_NAME = f'model_epoch{e}.pth'\n",
        "        MODEL_PATH = os.path.join(MODEL_DIR, MODEL_NAME)\n",
        "\n",
        "        torch.save({\n",
        "            'model_state_dict': unet.state_dict(),\n",
        "            'optim_state_dict': optimizer.state_dict(),\n",
        "            'epoch': e,\n",
        "            'loss_values': LOSS_VALS,\n",
        "            'accuracy_values': ACCURACY_VALS\n",
        "        }, MODEL_PATH)\n",
        "        print(f\"Epoch {e} completed! Avg Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "        print(\"Model successfully saved!\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "IDtQtYAGeVJc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_DIR_CITYSCAPES = '/content/drive/MyDrive/Cityscapes/'\n",
        "IMAGE_HEIGHT = 1024\n",
        "IMAGE_WIDTH = 2048\n",
        "\n",
        "MODEL_PATH = ROOT_DIR_CITYSCAPES + \"MODEL/model_epoch14.pth\"\n",
        "\n",
        "EVAL = True\n",
        "PLOT_LOSS = True\n",
        "\n",
        "def map_labels_to_colors(label):\n",
        "\n",
        "    if isinstance(label, Image.Image):\n",
        "        label = np.array(label)\n",
        "\n",
        "\n",
        "    color_mapped = np.zeros((label.shape[0], label.shape[1], 3), dtype=np.uint8)\n",
        "\n",
        "\n",
        "    for trainId, label_info in t2l.items():\n",
        "        color_mapped[label == trainId] = label_info.color\n",
        "\n",
        "    return color_mapped\n",
        "\n",
        "def plot_images(original_image, true_label, predicted_label, name):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    axes[0].imshow(original_image)\n",
        "    axes[0].set_title('Original Image')\n",
        "\n",
        "\n",
        "    axes[1].imshow(map_labels_to_colors(true_label))\n",
        "    axes[1].set_title('Ground Truth')\n",
        "\n",
        "    axes[2].imshow(map_labels_to_colors(predicted_label))\n",
        "    axes[2].set_title('Prediction')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'saved_images/multiclass_1/{name}_comparison.png')\n",
        "    plt.show()\n",
        "\n",
        "def save_predictions(data, model):\n",
        "    model.eval()\n",
        "    count = 0\n",
        "    total_pixels = 0\n",
        "    correct_pixels = 0\n",
        "    all_results = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(tqdm(data)):\n",
        "            if count == 5:\n",
        "                break\n",
        "            count += 1\n",
        "            X, y, s = batch\n",
        "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "            predictions = model(X)\n",
        "\n",
        "            predictions = torch.nn.functional.softmax(predictions, dim=1)\n",
        "            pred_labels = torch.argmax(predictions, dim=1)\n",
        "\n",
        "            pred_labels = pred_labels.squeeze().to('cpu').numpy()\n",
        "            y = y.squeeze().to('cpu').numpy()\n",
        "\n",
        "            unique_true_labels = np.unique(y)\n",
        "            unique_pred_labels = np.unique(pred_labels)\n",
        "\n",
        "            total_pixels += y.size\n",
        "            correct_pixels += np.sum(pred_labels == y)\n",
        "\n",
        "            pred_labels = np.vectorize(lambda x: t2l[x].id)(pred_labels)\n",
        "\n",
        "            pred_labels_resized = transforms.Resize((1024, 2048))(Image.fromarray(pred_labels.astype(np.uint8)))\n",
        "\n",
        "            original_image_resized = transforms.Resize((1024, 2048))(transforms.ToPILImage()(X.squeeze().cpu()))\n",
        "            true_label_resized = transforms.Resize((1024, 2048))(transforms.ToPILImage()(y.squeeze().astype(np.uint8)))\n",
        "\n",
        "            s = str(s)\n",
        "            pos = s.rfind('/', 0, len(s))\n",
        "            name = s[pos+1:-18]\n",
        "            location = 'saved_images/multiclass_1'\n",
        "            os.makedirs(location, exist_ok=True)\n",
        "\n",
        "            pred_image_path = os.path.join(location, f\"{name}_prediction.png\")\n",
        "            pred_labels_resized.save(pred_image_path)\n",
        "\n",
        "            all_results.append((original_image_resized, true_label_resized, pred_labels_resized, s))\n",
        "\n",
        "    accuracy = correct_pixels / total_pixels\n",
        "    print(f\"Pixel-wise Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    random.shuffle(all_results)\n",
        "    for i in range(5):\n",
        "        original_image, true_label, pred_label, s = all_results[i]\n",
        "        s = str(s)\n",
        "        pos = s.rfind('/', 0, len(s))\n",
        "        name = s[pos+1:-18]\n",
        "\n",
        "        plot_images(original_image, true_label, pred_label, name)\n",
        "\n",
        "def evaluate(path):\n",
        "    T = transforms.Compose([\n",
        "        transforms.Resize((IMAGE_HEIGHT, IMAGE_WIDTH), interpolation=Image.NEAREST)\n",
        "    ])\n",
        "\n",
        "    test_set = get_cityscapes_data(\n",
        "        root_dir=ROOT_DIR_CITYSCAPES,\n",
        "        split='train',\n",
        "        mode='fine',\n",
        "        relabelled=True,\n",
        "        transforms=T,\n",
        "        shuffle=True,\n",
        "        eval=True\n",
        "    )\n",
        "\n",
        "    print('Data has been loaded!')\n",
        "\n",
        "    net = UNET(in_channels=3, classes=19).to(DEVICE)\n",
        "    checkpoint = torch.load(path)\n",
        "    net.load_state_dict(checkpoint['model_state_dict'])\n",
        "    net.eval()\n",
        "    print(f'{path} has been loaded and initialized')\n",
        "    save_predictions(test_set, net)\n",
        "\n",
        "def plot_metrics(path):\n",
        "    checkpoint = torch.load(path)\n",
        "    losses = checkpoint['loss_values']\n",
        "\n",
        "    accuracies = checkpoint['accuracy_values']\n",
        "    epoch = checkpoint['epoch']\n",
        "\n",
        "    epoch_list = list(range(len(losses)))\n",
        "\n",
        "\n",
        "    if len(epoch_list) != len(losses):\n",
        "        raise ValueError(f\"Epochs ({len(epoch_list)}) and Loss values ({len(losses)}) must have the same length.\")\n",
        "\n",
        "    if len(epoch_list) != len(accuracies):\n",
        "        raise ValueError(f\"Epochs ({len(epoch_list)}) and Accuracy values ({len(accuracies)}) must have the same length.\")\n",
        "\n",
        "    fig, ax1 = plt.subplots()\n",
        "\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Loss', color='tab:red')\n",
        "    ax1.plot(epoch_list, losses, color='tab:red', label='Loss')\n",
        "    ax1.tick_params(axis='y', labelcolor='tab:red')\n",
        "\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.set_ylabel('Accuracy', color='tab:blue')\n",
        "    ax2.plot(epoch_list, accuracies, color='tab:blue', label='Accuracy')\n",
        "    ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
        "\n",
        "    plt.title(f\"Loss and Accuracy over {epoch+1} epoch/s\")\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if EVAL:\n",
        "        evaluate(MODEL_PATH)\n",
        "    if PLOT_LOSS:\n",
        "        plot_metrics(MODEL_PATH)"
      ],
      "metadata": {
        "id": "ERHTZxCNTKXb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "2yCe8Cs0qqYp"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}